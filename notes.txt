- make
- kompilacja kilku programow z jendym makiem



# Opcje GCC:
## Kompilacja i Linkowanie
	-o <filename>: wyjscie do pliku o wskazanej nazwie
	-c: kompiluje kod zrodlowy do obiektu
	-g: zawiera informacje dla debuggera
	-DDEBUG: pozwala na kompilacje kodu , ktory jest defined jako #DEBUG
	-I<directory>: dodaje katalog do przeszukania pod wzgledem plikow naglowkowych
	-L<directory>: dodaje katalog do przeszukania pod wzgledem biliotek
	-l<library>: linkuje ze wskazana biblioteka (bez prefixu "lib" i rozszerzenia)
	np. lpomiar_czasu lub lm (matematyczna)
## Optymalizacja
	-00: bez optymalizacji (default)
	-01: podstawowa optymalizacja wydajnosci i rozmiaru (drobny wplyw na czas kompilacji)
	-02: dalsza ooptymalizacja
	-03: maksymalna optymalizacja
	-0s: optymalizacja pod rozmiar
	
## Ostrzerzenia
	-Wall: uwzglednia wiekszosc ostrzerzen
	-Wextra: uwzglednia dodatkowe ostrzerzenia
	-Werror: traktuje ostrzerzenia jako bledy
	
## Standard C:
	-std=c17: specyfikuje standard C


# OpenMP:

	- omp_get_max_threads(): zwraca maksymalną ilość wątków
	- omp_get_thread_num(): zwraca numer wywołującego wątku
	- omp_set_nested(val): pozwala na zrównoleglenie pętli w pętli
		- val = 1: true
		- val = 0: false

Ustawianie liczby wątków:
	- export OMP_NUM_THREADS=4 (terminal)
	- klauzula #pragma omp num_threads(4)
	- funkcja omp_set_num_threads(4)

#pragma omp:
	- parallel: skecja równoległa, gdzie każdy wątek wykonuje ten sam kod
	- parallel for: zrównoleglenie pętli
	- default(arg): domyślny dostęp wątków do zmiennych
		- none: 
		- shared:
		- private:
	- shared(args): zmienne jakie mają być wspólne między watkami
	- private(args): zmienne jakie mają być prywatne między wątkami
	- reduction(type, var): wspólna zmienna wynikowa. Kazdy wątek ma kopie lokalną po zakończeniu pracy sa one łączone
		- type:	rodzaj operacji
			- +: wyniki lokalne są sumowane
			- *: wyniki lokalne są mnożone
			- max: w zmiennej wynikowej zapisywany jest maksymalna lokalna (chyba, że wynikowa była już większa. Najlepiej zaincjowac jako INT_MIN)
			- min: w zmiennej wynikowej zapisujemy minimum (chyba, że wynikowa była mniejsza. Najlepiej ją zainicjować jako INT_MAX)
		- var: zmienna
	- schedule(type, number): sposób podziału pętli między wątki
		- type:
			- static: (domyślny sposób). Stały podział, defaultowo liczba_iteracji/liczba_wątków
			- dynamic: dynamiczny podział. Wątek który skończył swoją pracę dostaje kolejny zestaw. Defaultowo 1
		number: wielkość zestawu
	- ordered{ code }: sekcja w pętli, która będzie synchronizowana pomiędzy wątkami. Pętla musi mieć klauzulę ordered. Możliwe, że nawias musi być blokowy Allmana
	- critical(nazwa): sekcja krytyczna
		- nazwa: opcjonalna. Nazwa indetyfikująca, tj. użytego muteksu
		
		

# Open MPI

int MPI_Init(int *argc, char ***argv);
	- Inicjalizuje środowisko Open MPI.
	- Zwraca kod statusu (== MPI_SUCCESS).
	- Parametry:
		- argc: ilosc argumentow przekazanych main.
		- argv: tablica argumentow.
		
int MPI_Comm_rank(MPI_Comm comm, int *rank);
	- Pobiera range procesu
	- Zwraca kod statusu (== MPI_SUCCESS).
	- Parametry:
		- comm: Komunikator (np. MPI_COMM_WORLD).
		- *rank: wskaźnik do miejsca gdzie zostanie zapisana ranga procesu.
		
int MPI_Comm_size(MPI_Comm comm, int *size);
	- Pobiera liczbe procesów w komunikatorze
	- Zwraca kod statusu (== MPI_SUCCESS).
		
int MPI_Send(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm);
	- Wysyła dane z bufora do innego procesu w komunikatorze.
	- Zwraca kod statusu.
	- Parametry:
		- *buf: wskaźnik do bufora z danymi do wysłania.
		- count: liczba elementów w buforze.
		- datatype: typ danych.
		- dest: ranga procesu docelowego.
		- tag: id transferu.
		- comm: komunikator.
		
int MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status);
	- Odbiera dane od innego procesU w komunikatorze.
	- Zwraca kod statusu.
	- Parametry:
		- *buf: Wskaźnik do miejsca na zapis.
		- count: ilość elementów.
		- datatype: typ danych.
		- source: ranga procesu wysylajacego lub (MPI_ANY_SOURCE).
		- tag: id wiadomosci lub (MPI_ANY_TAG).
		- comm: Komunikator.
		- status: struktura z info o komunikacie.

int MPI_Finalize();
	- Zakańcza środowisko i zwlania zasoby.
	- Zwraca kod statusu.
	
int gethostname(char *name, size_t len);
	- Biblioteka unistd.h


MPI_DATATYPE:
	- MPI_INT (int).	
	- MPI_LONG (long).
	- MPI_SHORT (short).
	- MPI_UNSIGNED (unsigned int).
	- MPI_BYTE.
	- MPI_FLOAT (float).
	- MPI_DOUBLE (double)
	- MPI_LONG_DOUBLE (long double).
	- MPI_CHAR (char).
	- MPI_C_BOOL (bool).
	- MPI_PACKED - spakowane dane.
	
	
	
Przesyłanie i odbieranie komunikatów (punkt - punkt)
- Jeden proces wysyła dane.
- Drugi proces odbiera dane.

MPI_Send i MPI_Recv
- Blokujące operacje.
- Proces wysyłający czeka, aż dane zostaną skopiowane do systemowego bufora lub odbiorca odbierze dane.
- Proces odbierający czeka na przyjście danych.

MPI_ISend i MPI_IRecv
- Nieblokujące operacje.
- Zwracają natychmiast po rozpoczęciu operacji.
- Używają uchwytów (MPI_Request) do śledzenia stanu operacji.


MPI_Request send_request, recv_request;
MPI_Status status;

// Nieblokujące wysyłanie
int data = 42;
MPI_ISend(&data, 1, MPI_INT, dest, tag, MPI_COMM_WORLD, &send_request);

// Nieblokujące odbieranie
int received_data;
MPI_IRecv(&received_data, 1, MPI_INT, MPI_ANY_SOURCE, tag, MPI_COMM_WORLD, &recv_request);

// Synchronizacja operacji
MPI_Wait(&send_request, &status);
MPI_Wait(&recv_request, &status);

Pamięć dzielona:
- W pamięci dzielonej wszystkie procesy mają dostęp do tej samej przestrzeni pamięci.
- Zamiast przesyłać dane między procesami, procesy odczytują i zapisują je bezpośrednio w tej samej pamięci.
- Synchronizacja jest jawna.
- Może być szybsza, ale to zależy bardzo od implementacji.

kod:
	int *shared_data;
	MPI_Win win;
	MPI_Win_allocate_shared(sizeof(int), sizeof(int), MPI_INFO_NULL, MPI_COMM_WORLD, &shared_data, &win);

int MPI_Bcast(void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm);
int MPI_Reduce(const void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm);
